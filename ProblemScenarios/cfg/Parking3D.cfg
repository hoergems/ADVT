# General-purpose settings.
verbose = false
logPath = log
overwriteExistingLogFiles = true
logFilePostfix =
saveParticles = false

[plugins]
heuristicPlugin = libparkingHeuristicPlugin.so

planningRewardPlugin = libparkingRewardPlugin.so
executionRewardPlugin = libparkingRewardPlugin.so

planningTerminalPlugin = libparkingTerminalPlugin.so
executionTerminalPlugin = libparkingTerminalPlugin.so

planningTransitionPlugin = libparkingTransitionPlugin.so
executionTransitionPlugin = libparkingTransitionPlugin.so

planningObservationPlugin = libparkingObservationPlugin.so
executionObservationPlugin = libparkingObservationPlugin.so

executionInitialBeliefPlugin = libparkingInitialBeliefPlugin.so
planningInitialBeliefPlugin = libparkingInitialBeliefPlugin.so

[initialBeliefOptions]
positionError = 0.175

[transitionPluginOptions]
controlDuration = 1.0
#controlDuration = 0.0
controlErrorElevation = 0.0
controlErrorVelocity = 0.0
controlErrorYaw = 0.0
numIntegrationSteps = 3

[observationPluginOptions]
correctObservationProbability = 0.7

[rewardPluginOptions]
stepPenalty = 1.0
exitReward = 100.0
collisionPenalty = 100.0

[heuristicPluginOptions]

[problem]
robotName = Vehicle

# Number of simulation runs
nRuns = 1

# Maximum number of steps to reach the goal
nSteps = 50

# The planning environment SDF
planningEnvironmentPath = Parking3DEnvironment.sdf

# The execution environment SDF
executionEnvironmentPath = Parking3DEnvironment.sdf

enableGazeboStateLogging = false

# The discount factor of the reward model
discountFactor = 0.95

# The maximum time to spend on each step, in milliseconds (0 => no time limit)
stepTimeout = 1000

[vehicle]
vehicleLink = Vehicle::link

##################################################################################################
##################################################################################################
#### State, action and observation description
##################################################################################################
##################################################################################################
[state]
additionalDimentions = 5
additionalDimensionLimits = [[-100.0, 100.0], [-100.0, 100.0], [-100.0, 100.0], [-100.0, 100.0], [-100.0, 100.0]]

[action]
additionalDimensions = 3
additionalDimensionLimits = [[-8.0, 8.0], [-1.57, 1.57], [-3.5, 3.5]]

[observation]
additionalDimensions = 4
additionalDimensionLimits = [[-10, 10], [-10, 10], [-10, 10]]

[ADVT]
numEpisodes = 0
maximumDepth = 3
minParticleCount = 1000
maxObservationDistance = 1.0

explorationFactor = 2.0
splitExplorationFactor = 50.5
explorationFactorDiameter = 15.25

numDiameterSamples = 10
resetTree = false
rejectionSampling = false

partitioningMode = VORONOI
bellmanBackup = true

[simulation]
interactive = false
particlePlotLimit = 0
